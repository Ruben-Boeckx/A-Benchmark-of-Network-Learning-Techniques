{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from preprocessing.feature_engineering import FeatureEngineering\n",
    "from preprocessing.Resampling import Resampling\n",
    "from graph.graph_construction import GraphConstruction\n",
    "from models.GNNs import GraphSAGE, GAT, GraphSAGE2, GAT2, GAT3\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch_geometric.nn import to_hetero\n",
    "from torch_geometric.loader import HGTLoader\n",
    "from sklearn.metrics import average_precision_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering completed.\n",
      "Fraud rate in training set before resampling: 0.54%\n",
      "Fraud rate in testing set: 0.62%\n",
      "Fraud rate in training set after resampling: 50.00%\n",
      "Fraud rate in testing set after resampling: 0.62%\n",
      "Length of training set: 953192\n",
      "Length of testing set: 198889\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('C:/Users/ruben/OneDrive/Desktop/Datasets/original_dataset.csv')\n",
    "\n",
    "# Apply feature engineering on the dataset\n",
    "fe = FeatureEngineering(dataset)\n",
    "processed_dataset = fe.apply_feature_engineering()\n",
    "\n",
    "# Apply resampling on the dataset\n",
    "resampler = Resampling(processed_dataset, test_size=0.4, random_state=42)\n",
    "final_dataset = resampler.apply_resampling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.head()\n",
    "final_dataset.to_csv('C:/Users/ruben/OneDrive/Desktop/Datasets/final_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud Percentage in Train Mask: 50.00%\n",
      "Fraud Percentage in Test Mask: 0.61%\n",
      "Fraud Percentage in Val Mask: 0.63%\n",
      "Graph Construction Successful!\n"
     ]
    }
   ],
   "source": [
    "final_dataset = pd.read_csv('C:/Users/ruben/OneDrive/Desktop/Datasets/final_dataset.csv')\n",
    "\n",
    "# Percentage in Test and Val set is not the same because there is no stratified split performed\n",
    "graph_constructor = GraphConstruction(final_dataset)\n",
    "data = graph_constructor.apply_graph_construction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  transaction={\n",
      "    x=[1152081, 7],\n",
      "    y=[1152081],\n",
      "    num_classes=2,\n",
      "    train_mask=[1152081],\n",
      "    test_mask=[1152081],\n",
      "    val_mask=[1152081],\n",
      "  },\n",
      "  client={ x=[983, 5] },\n",
      "  merchant={ x=[693, 1] },\n",
      "  (client, pays, transaction)={ edge_index=[2, 1152081] },\n",
      "  (transaction, received by, merchant)={ edge_index=[2, 1152081] },\n",
      "  (transaction, rev_pays, client)={ edge_index=[2, 1152081] },\n",
      "  (merchant, rev_received by, transaction)={ edge_index=[2, 1152081] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GINConv, HeteroConv\n",
    "\n",
    "class HeteroGINLayer(nn.Module):\n",
    "    def __init__(self, in_channels_dict, hidden_channels, node_types, edge_types, is_first_layer=False):\n",
    "        super(HeteroGINLayer, self).__init__()\n",
    "        \n",
    "        self.lin_dict = nn.ModuleDict()\n",
    "        for node_type in node_types:\n",
    "            if is_first_layer:\n",
    "                self.lin_dict[node_type] = nn.Linear(in_channels_dict[node_type], hidden_channels)\n",
    "            else:\n",
    "                self.lin_dict[node_type] = nn.Identity()  # No projection needed after first layer\n",
    "        \n",
    "        gin_nn = lambda in_dim: nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, hidden_channels)\n",
    "        )\n",
    "        \n",
    "        self.conv = HeteroConv({\n",
    "            edge_type: GINConv(gin_nn(hidden_channels if is_first_layer else hidden_channels))\n",
    "            for edge_type in edge_types\n",
    "        })\n",
    "        \n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict = {key: self.lin_dict[key](x) for key, x in x_dict.items()}\n",
    "        return self.conv(x_dict, edge_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroGIN(nn.Module):\n",
    "    def __init__(self, in_channels_dict, hidden_channels, num_layers, data):\n",
    "        super(HeteroGIN, self).__init__()\n",
    "        \n",
    "        self.node_types = data.node_types\n",
    "        self.edge_types = data.edge_types\n",
    "        \n",
    "        self.convs = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            conv = HeteroGINLayer(in_channels_dict, hidden_channels, self.node_types, self.edge_types, is_first_layer=(i==0))\n",
    "            self.convs.append(conv)\n",
    "        \n",
    "        self.lin = nn.Linear(hidden_channels, data['transaction'].num_classes)\n",
    "        \n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "            x_dict = {key: x.relu() for key, x in x_dict.items()}\n",
    "        \n",
    "        return self.lin(x_dict['transaction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels_dict = {\n",
    "    'transaction': 7,\n",
    "    'client': 5,\n",
    "    'merchant': 1\n",
    "}\n",
    "\n",
    "model = HeteroGIN(in_channels_dict=in_channels_dict, hidden_channels=64, num_layers=3, data=data)\n",
    "data, model = data.to(device), model.to(device)\n",
    "\n",
    "x_dict = {node_type: data[node_type].x for node_type in data.node_types}\n",
    "edge_index_dict = {edge_type: data[edge_type].edge_index for edge_type in data.edge_types}\n",
    "\n",
    "out = model(x_dict, edge_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, optimizer, data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    out = out[data['transaction'].train_mask].float()\n",
    "    target = data['transaction'].y[data['transaction'].train_mask].long()\n",
    "    loss = F.cross_entropy(out, target)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data, mask):\n",
    "    model.eval()\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    out = out[mask].float()\n",
    "    pred = out.argmax(dim=1)\n",
    "    true = data['transaction'].y[mask].long()\n",
    "    \n",
    "    accuracy = accuracy_score(true.cpu().numpy(), pred.cpu().numpy())\n",
    "    f1 = f1_score(true.cpu().numpy(), pred.cpu().numpy(), average='binary')\n",
    "    \n",
    "    return accuracy, f1\n",
    "\n",
    "def main(data, model, epochs=100, lr=0.01, weight_decay=5e-4):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    data = data.to(device)\n",
    "    \n",
    "    for key in data.x_dict:\n",
    "        data.x_dict[key] = data.x_dict[key].float()\n",
    "    data['transaction'].y = data['transaction'].y.long()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    best_val_f1 = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        loss = train(model, optimizer, data)\n",
    "        train_acc, train_f1 = test(model, data, data['transaction'].train_mask)\n",
    "        val_acc, val_f1 = test(model, data, data['transaction'].val_mask)\n",
    "        \n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            best_model = model.state_dict()\n",
    "        \n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, '\n",
    "              f'Train F1: {train_f1:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}')\n",
    "    \n",
    "    # Load best model and test\n",
    "    model.load_state_dict(best_model)\n",
    "    test_acc, test_f1 = test(model, data, data['transaction'].test_mask)\n",
    "    print(f'Test Accuracy: {test_acc:.4f}, Test F1: {test_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [02:14<3:41:16, 134.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 4.0738, Train Acc: 0.5169, Train F1: 0.6702, Val Acc: 0.0447, Val F1: 0.0130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [04:26<3:37:06, 132.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 74.3193, Train Acc: 0.5000, Train F1: 0.0000, Val Acc: 0.9937, Val F1: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [06:22<3:22:31, 125.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Loss: 389.4279, Train Acc: 0.5000, Train F1: 0.0000, Val Acc: 0.9937, Val F1: 0.0000\n"
     ]
    }
   ],
   "source": [
    "in_channels_dict = {\n",
    "    'transaction': 7,\n",
    "    'client': 5,\n",
    "    'merchant': 1\n",
    "}\n",
    "\n",
    "model = HeteroGIN(in_channels_dict=in_channels_dict, hidden_channels=64, num_layers=3, data=data)\n",
    "\n",
    "# Run the training and testing pipeline\n",
    "main(data, model, epochs=100, lr=0.01, weight_decay=5e-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
